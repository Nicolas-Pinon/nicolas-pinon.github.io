---
title: "Improving motion‐mask segmentation in thoracic CT with multiplanar U‐nets"
collection: research
permalink: /research/manuscript_final_author_version.pdf
excerpt: 'Motion‐mask segmentation from thoracic computed tomography (CT) images is the process of extracting the region that encompasses lungs and viscera, where large displacements occur during breathing. It has been shown to help image registration between different respiratory phases. This registration step is, for example, useful for radiotherapy planning or calculating local lung ventilation. Knowing the location of motion discontinuity, that is, sliding motion near the pleura, allows a better control of the registration preventing unrealistic estimates. Nevertheless, existing methods for motion‐mask segmentation are not robust enough to be used in clinical routine. This article shows that it is feasible to overcome this lack of robustness by using a lightweight deep‐learning approach usable on a standard computer, and this even without data augmentation or advanced model design.'
date: 2022-01-01
venue: 'Medical Physics'
paperurl: 'https://hal.science/hal-03464276/file/manuscript_final_author_version.pdf'
citation: 'Ludmilla Penarrubia, <b>Nicolas Pinon</b>, Emmanuel Roux, Eduardo Enrique Dávila Serrano, Jean‐Christophe Richard, Maciej Orkisz, David Sarrut (2022). &quot;Improving motion‐mask segmentation in thoracic CT with multiplanar U‐nets.&quot; <i>Medical Physics</i>.'
---

The contents above will be part of a list of publications, if the user clicks the link for the publication than the contents of section will be rendered as a full page, allowing you to provide more information about the paper for the reader. When publications are displayed as a single page, the contents of the above "citation" field will automatically be included below this section in a smaller font.

Motion‐mask segmentation from thoracic computed tomography (CT) images is the process of extracting the region that encompasses lungs and viscera, where large displacements occur during breathing. It has been shown to help image registration between different respiratory phases. This registration step is, for example, useful for radiotherapy planning or calculating local lung ventilation. Knowing the location of motion discontinuity, that is, sliding motion near the pleura, allows a better control of the registration preventing unrealistic estimates. Nevertheless, existing methods for motion‐mask segmentation are not robust enough to be used in clinical routine. This article shows that it is feasible to overcome this lack of robustness by using a lightweight deep‐learning approach usable on a standard computer, and this even without data augmentation or advanced model design.


